CREATE USER admin IDENTIFIED WITH plaintext_password BY admin GRANT ANY

https://clickhouse.com/docs/en/interfaces/cli/  <-- qui ci sono i comandi per il login e altro

clickhouse-client -u user --password

cat ~/CSVs/sales/cleaned/edit-sales-2M.tsv | clickhouse-client -u default --password default -q "INSERT INTO sales.2m FORMAT TSVWithNames"

create materialized view sales.itemtype_totalrevenue Engine=SummingMergeTree() order by `Item Type` populate as select `Item Type`, sum(`Total Revenue`) from sales.5mtree group by `Item Type`

create materialized view itemtype_totalprofit2 Engine=SummingMergeTree() order by `Item Type` populate as select `Item Type`,`Total Profit` from sales.5mtree group by `Item Type`

create materialized view profit Engine=ReplacingMergeTree() order by `Region` populate as select `Item Type`,`Region`,`Total Profit` from sales.5mtree group by `Item Type`,`Region`



grant all on *.* to admin with grant option


 USER admin IDENTIFIED BY '<new password>'

DROP USER <username>

select currentDatabase()

select currentUser()

use db_name <--seleziona il database

show tables <--mostra le tabelle nel database selezionato


create table sales.5mSum(
	"Region" String,
	"Country" String,
	"Item Type" String,
	"Sales Channel" String,
	"Order Priority" String,
	"Order Date" Date,
	"Order ID" Int32,
	"Ship Date" Date,
	"Units Sold" Int16,
	"Unit Price" Float32,
	"Unit Cost" Float32,
	"Total Revenue" Float64,
	"Total Cost" Float64,
	"Total Profit" Float64
	)
	ENGINE = SummingMergeTree()
	order by `Order ID`
	
create table sales.2m(
	Region String,
	Country String,
	ItemType String,
	SalesChannel String,
	OrderPriority String,
	OrderDate Date,
	OrderID Int32,
	ShipDate Date,
	UnitsSold Int16,
	UnitPrice Float32,
	UnitCost Float32,
	TotalRevenue Float64,
	TotalCost Float64,
	TotalProfit Float64
	)
	ENGINE = MergeTree()
    order by OrderID
	
headers = ['Region',
	'Country',
	'ItemType',
	'SalesChannel',
	'OrderPriority',
	'OrderDate',
	'OrderID',
	'ShipDate',
	'UnitsSold',
	'UnitPrice',
	'UnitCost',
	'TotalRevenue',
	'TotalCost',
	'TotalProfit'
	]
	
	
https://stackoverflow.com/questions/60174383/how-do-i-change-the-date-format-from-mm-dd-yyyy-to-dd-mm-yyyy-in-libreoffice-cal

https://glogg.bonnefon.org/download.html


cat ~/CSVs/sales/cleaned/edit-sales-5M.csv | clickhouse-client -u admin --password admin --query="INSERT INTO sales.sales5 SELECT ItemType, toDate(parseDateTimeBestEffort(OrderDate)) AS OrderDate from input('ItemType String,OrderDate String') FORMAT CSVWithNames"


cat ~/Downloads/sales-2m.csv | clickhouse-client -u admin --password admin --query="INSERT INTO sales.sales2m SELECT Region, Country, ItemType, SalesChannel, OrderPriority, toDate(parseDateTimeBestEffort(OrderDate)) AS OrderDate, OrderID, toDate(parseDateTimeBestEffort(ShipDate)) AS ShipDate, UnitsSold, UnitPrice, UnitCost, TotalRevenue, TotalCost, TotalProfit from input('Region String, Country String, ItemType String, SalesChannel String, OrderPriority String, OrderDate String, OrderID Int32, ShipDate String, UnitsSold Int16, UnitPrice Float32, UnitCost Float32, TotalRevenue Float64, TotalCost Float64, TotalProfit Float64') FORMAT CSVWithNames"


Alla fine basta utilizzare un piccolo script python per convertire tutte le colonne
con le date nel formato sbagliato in quello giusto, e poi popolare la tabella semplicemente
con: 

cat ./Downloads/sales-100.csv | clickhouse-client -u admin --password admin -q "INSERT INTO sales.sales FORMAT CSVWithNames"

N.B. pandas aggiunge automaticamente una colonna(riga) con degli indici di riga in ordine crescete da 0->len(file.csv) ma non mette il nome di questa nuova colonna, mette solo una virgola prima della prima colonna. Quindi occorre evitare questa cosa oppure mettere un nome alla colonna  e creare la tabella di conseguenza

per evitare aggiungere il parametro index=False come parametro di to_csv()
parametro header=False per non scrivere nel file gli header (nomi colonne)




rename table old_name to new_name


create table sales.sale5(
	ItemType String,
	OrderDate Date
	)
	ENGINE = Log()
	
truncate table nome_tabella <-- cancella il contenuto ma non la tabella


create table bt.bt100(
	"Date" Date,
	"Description" String,
	"Deposits" Float32,
	"Withdrawls" Float32,
	"Balance" Float32
	)
	engine = MergeTree()
	order by Date
	
cat ~/CSVs/bt/cleaned/edit-bt100.csv | clickhouse-client -u admin --password admin -q "INSERT INTO bt.bt100 SELECT Date, Description, toFloat32OrZero(toString(Deposits)) AS Deposits, toFloat32OrZero(toString(Withdrawls)) AS Withdrawls, toFloat32OrZero(toString(Balance)) AS Balance FROM input('Date Date,Description String,Deposits String,Withdrawls String,Balance String') FORMAT CSVWithNames"

cat ~/CSVs/bt/cleaned/edit-bt100.tsv | clickhouse-client -u admin --password admin -q "INSERT INTO bt.bt100 FORMAT TSVWithNames"
	
	
insert into 5mSum ( `Region`,
	`Country`,
	`Item Type`,
	`Sales Channel`,
	`Order Priority`,
	`Order Date`,
	`Order ID`,
	`Ship Date`,
	`Units Sold`,
	`Unit Price`,
	`Unit Cost`,
	`Total Revenue`,
	`Total Cost`,
	`Total Profit`)
	values ( 'Europe',
	'Italy',
	'Fruits',
	'Offline',
	'M',
	2020-04-18,
	9999999876,
	2020-05-18,
	44,
	90.9,
	78.8,
	36000.29,
	15000.2,
	21000.09
	)
	
	
create table sales.supersales3(
	id String,
	Gender String,
	ProductLine String,
	UnitPrice Float32,
	Quantity UInt16,
	Date Date
	)
	Engine=ReplacingMergeTree()
	order by Gender

create table chpv.dump2(
    cod_cli_for UInt16, 
    rag_soc String, 
    cod_prod String, 
    descr_prod String, 
    data_doc UInt64, 
    data_format_date Date, 
    qta Float64, 
    val Float64,
    flag_off UInt16
    )
Engine=MergeTree()
order by data_format_date
//XXX
cat ~/CSVs/newdump2.tsv | clickhouse-client -u savato --password savato -q "INSERT INTO chpv.dump2 FORMAT TSVWithNames"

cat ~/CSVs/newdump.tsv | clickhouse-client -u savato --password savato -q "INSERT INTO chpv.dump2 ("cod_cli_for","rag_soc","cod_prod","descr_prod","data_doc","data_format_date","qta","val","flag_off") FORMAT TSV"

Creando una tabella con MergeTree o simili, la chiave che si mette in order by 
deve essere univoca.
Mettendo Gender (={'Male','Female'})


insert into supersales (*) values ('111-111-111', 'Male', 'Sports and travel', 20, 7, 2022-05-21)

ssh pentaho@192.168.89.60 "mysqldump -u bi -p chpv.view_pv_tabellone | gzip -9" > ./dblocal.sql.gz

ssh pentaho@192.168.89.60 "clickhouse-client -u bi --password chpv.view_pv_tabellone | gzip -9" > ./dblocal.sql.gz 

SELECT cod_cli_for, rag_soc, cod_prod, descr_prod, data_doc, data_format_date, qta_offerta, qta_non_offerta, val_off, val_non_off FROM chpv.view_pv_tabellone INTO OUTFILE 'dump.tsv'

scp pentaho@192.168.89.60:/home/pentaho/dump.tsv ./CSVs/

insert into mindsdb.predictors(name,predict,select_data_query) values ('testPredictor', 'quantity', 'select * from sales.supersales')

python3 -m mindsdb --api=mysql --config=/home/savato/mindsdb1/config.json


python3 -m mindsdb --api mysql --config ./config.json

INSERT INTO predictors(name, predict, select_data_query) VALUES ('qpredictor', 'Quantity', 'SELECT * FROM sales.supersales')

INSERT INTO predictors(name, predict, select_data_query) VALUES ('unitpredictor8', 'Units Sold', 'SELECT * FROM sales.5mtree limit 10000')

alter table predictors delete where name='qpredictor'

select `Units Sold` as predicted from unitpredictor2 where Region='Italy' and `Item Type`='Beverages' format Vertical

create table chpv.dump(
    


t9cG5gYtf5nBtCzd


iptables -I INPUT -p tcp -s 18.220.205.95 -j ACCEPT
iptables -I OUTPUT -p tcp -d  18.220.205.95 -j ACCEPT

iptables -I INPUT -p tcp -s 3.19.152.46 -j ACCEPT
iptables -I OUTPUT -p tcp -d  3.19.152.46 -j ACCEPT

iptables -I INPUT -p tcp -s 52.14.91.162 -j ACCEPT
iptables -I OUTPUT -p tcp -d  52.14.91.162 -j ACCEPT

/etc/init.d/networking restart  








